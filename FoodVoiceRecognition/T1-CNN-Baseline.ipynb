{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!wget http://tianchi-competition.oss-cn-hangzhou.aliyuncs.com/531887/train_sample.zip"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-04-11 12:39:16--  http://tianchi-competition.oss-cn-hangzhou.aliyuncs.com/531887/train_sample.zip\n",
            "Resolving tianchi-competition.oss-cn-hangzhou.aliyuncs.com (tianchi-competition.oss-cn-hangzhou.aliyuncs.com)... 118.31.232.194\n",
            "Connecting to tianchi-competition.oss-cn-hangzhou.aliyuncs.com (tianchi-competition.oss-cn-hangzhou.aliyuncs.com)|118.31.232.194|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 540689175 (516M) [application/zip]\n",
            "Saving to: ‘train_sample.zip.1’\n",
            "\n",
            "train_sample.zip.1  100%[===================>] 515.64M  5.85MB/s    in 95s     \n",
            "\n",
            "2021-04-11 12:40:52 (5.43 MB/s) - ‘train_sample.zip.1’ saved [540689175/540689175]\n",
            "\n"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "* unzip -qq \r\n",
        " \r\n",
        " -q     perform operations quietly (-qq = even quieter).  Ordinarily unzip prints the names of the files it's extracting or testing, the extrac‐\r\n",
        "              tion  methods,  any  file or zipfile comments that may be stored in the archive, and possibly a summary when finished with each archive.\r\n",
        "              The -q[q] options suppress the printing of some or all of these messages."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq train_sample.zip\n",
        "!\\rm train_sample.zip"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://tianchi-competition.oss-cn-hangzhou.aliyuncs.com/531887/test_a.zip"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-04-11 12:47:46--  http://tianchi-competition.oss-cn-hangzhou.aliyuncs.com/531887/test_a.zip\n",
            "Resolving tianchi-competition.oss-cn-hangzhou.aliyuncs.com (tianchi-competition.oss-cn-hangzhou.aliyuncs.com)... 118.31.232.194\n",
            "Connecting to tianchi-competition.oss-cn-hangzhou.aliyuncs.com (tianchi-competition.oss-cn-hangzhou.aliyuncs.com)|118.31.232.194|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1092637852 (1.0G) [application/zip]\n",
            "Saving to: ‘test_a.zip’\n",
            "\n",
            "test_a.zip          100%[===================>]   1.02G  6.03MB/s    in 3m 12s  \n",
            "\n",
            "2021-04-11 12:50:59 (5.42 MB/s) - ‘test_a.zip’ saved [1092637852/1092637852]\n",
            "\n"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq test_a.zip\n",
        "!\\rm test_a.zip"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 环境要求\n",
        "\n",
        "- TensorFlow的版本：2.0 + \n",
        "- keras\n",
        "- sklearn\n",
        "- librosa"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# 基本库\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1618145996224
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 加载深度学习框架"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# 搭建分类模型所需要的库\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, Dropout\n",
        "from tensorflow.keras.utils import to_categorical \n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1618145882174
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 加载音频处理库"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa --user"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting librosa\n",
            "  Downloading librosa-0.8.0.tar.gz (183 kB)\n",
            "\u001b[K     |████████████████████████████████| 183 kB 20.4 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting audioread>=2.0.0\n",
            "  Downloading audioread-2.1.9.tar.gz (377 kB)\n",
            "\u001b[K     |████████████████████████████████| 377 kB 43.3 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from librosa) (1.18.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from librosa) (1.5.2)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from librosa) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.14 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from librosa) (0.14.1)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from librosa) (4.4.2)\n",
            "Collecting resampy>=0.2.2\n",
            "  Downloading resampy-0.2.2.tar.gz (323 kB)\n",
            "\u001b[K     |████████████████████████████████| 323 kB 55.1 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: numba>=0.43.0 in /home/azureuser/.local/lib/python3.6/site-packages (from librosa) (0.53.0)\n",
            "Collecting soundfile>=0.9.0\n",
            "  Downloading SoundFile-0.10.3.post1-py2.py3-none-any.whl (21 kB)\n",
            "Collecting pooch>=1.0\n",
            "  Downloading pooch-1.3.0-py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 87 kB/s s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: six>=1.3 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from numba>=0.43.0->librosa) (50.3.0)\n",
            "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /home/azureuser/.local/lib/python3.6/site-packages (from numba>=0.43.0->librosa) (0.36.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from soundfile>=0.9.0->librosa) (1.14.4)\n",
            "Collecting appdirs\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: packaging in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from pooch>=1.0->librosa) (20.9)\n",
            "Requirement already satisfied: requests in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from pooch>=1.0->librosa) (2.25.1)\n",
            "Requirement already satisfied: pycparser in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from cffi>=1.0->soundfile>=0.9.0->librosa) (2.20)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from packaging->pooch>=1.0->librosa) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests->pooch>=1.0->librosa) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests->pooch>=1.0->librosa) (2020.12.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests->pooch>=1.0->librosa) (1.25.11)\n",
            "Building wheels for collected packages: librosa, audioread, resampy\n",
            "  Building wheel for librosa (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\n",
            "\u001b[?25h  Created wheel for librosa: filename=librosa-0.8.0-py3-none-any.whl size=201376 sha256=da482419b9b0bbb2da4c099aae75713379a8f28fd39d240400b828d822c0acd7\n",
            "  Stored in directory: /home/azureuser/.cache/pip/wheels/32/2c/ce/86e49d4769aceba728421c24c0d726054bf4ca01175ff42bdd\n",
            "  Building wheel for audioread (setup.py) ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Created wheel for audioread: filename=audioread-2.1.9-py3-none-any.whl size=23140 sha256=a71cb186d041dcd65e7ca41deb4ba9f46a0c6b72be6172f7f86a19517d386898\n",
            "  Stored in directory: /home/azureuser/.cache/pip/wheels/de/14/0a/863e4ed680b3204444cf486733e609d7ff7abe8fceafab67dc\n",
            "  Building wheel for resampy (setup.py) ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Created wheel for resampy: filename=resampy-0.2.2-py3-none-any.whl size=320718 sha256=75e20a062455d3c4a05fde8eabe680addad1659e314838bddb18e6264b4035a7\n",
            "  Stored in directory: /home/azureuser/.cache/pip/wheels/cf/d4/04/49d8824a42bd9f9b11d502727965b9997f0d41d2b22ae4f645\n",
            "Successfully built librosa audioread resampy\n",
            "Installing collected packages: audioread, resampy, soundfile, appdirs, pooch, librosa\n",
            "Successfully installed appdirs-1.4.4 audioread-2.1.9 librosa-0.8.0 pooch-1.3.0 resampy-0.2.2 soundfile-0.10.3.post1\n"
          ]
        }
      ],
      "execution_count": 8,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# 其他库\n",
        "\n",
        "import os\n",
        "import librosa\n",
        "import librosa.display\n",
        "import glob "
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1618145926089
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 特征提取以及数据集的建立"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "feature = []\n",
        "label = []\n",
        "# 建立类别标签，不同类别对应不同的数字。\n",
        "label_dict = {'aloe': 0, 'burger': 1, 'cabbage': 2,'candied_fruits':3, 'carrots': 4, 'chips':5,\n",
        "                  'chocolate': 6, 'drinks': 7, 'fries': 8, 'grapes': 9, 'gummies': 10, 'ice-cream':11,\n",
        "                  'jelly': 12, 'noodles': 13, 'pickles': 14, 'pizza': 15, 'ribs': 16, 'salmon':17,\n",
        "                  'soup': 18, 'wings': 19}\n",
        "label_dict_inv = {v:k for k,v in label_dict.items()}"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1618145941189
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "def extract_features(parent_dir, sub_dirs, max_file=10, file_ext=\"*.wav\"):\n",
        "    c = 0\n",
        "    label, feature = [], []\n",
        "    for sub_dir in sub_dirs:\n",
        "        for fn in tqdm(glob.glob(os.path.join(parent_dir, sub_dir, file_ext))[:max_file]): # 遍历数据集的所有文件\n",
        "            \n",
        "           # segment_log_specgrams, segment_labels = [], []\n",
        "            #sound_clip,sr = librosa.load(fn)\n",
        "            #print(fn)\n",
        "            label_name = fn.split('/')[-2]\n",
        "            label.extend([label_dict[label_name]])\n",
        "            X, sample_rate = librosa.load(fn,res_type='kaiser_fast')\n",
        "            mels = np.mean(librosa.feature.melspectrogram(y=X,sr=sample_rate).T,axis=0) # 计算梅尔频谱(mel spectrogram),并把它作为特征\n",
        "            feature.extend([mels])\n",
        "            \n",
        "    return [feature, label]"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1618145948678
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 自己更改目录\n",
        "parent_dir = './train_sample/'\n",
        "save_dir = \"./\"\n",
        "folds = sub_dirs = np.array(['aloe','burger','cabbage','candied_fruits',\n",
        "                             'carrots','chips','chocolate','drinks','fries',\n",
        "                            'grapes','gummies','ice-cream','jelly','noodles','pickles',\n",
        "                            'pizza','ribs','salmon','soup','wings'])\n",
        "\n",
        "# 获取特征feature以及类别的label\n",
        "temp = extract_features(parent_dir,sub_dirs,max_file=100)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 45/45 [00:04<00:00,  9.39it/s]\n",
            "100%|██████████| 64/64 [00:05<00:00, 10.98it/s]\n",
            "100%|██████████| 48/48 [00:07<00:00,  6.35it/s]\n",
            "100%|██████████| 74/74 [00:11<00:00,  6.71it/s]\n",
            "100%|██████████| 49/49 [00:07<00:00,  6.92it/s]\n",
            "100%|██████████| 57/57 [00:08<00:00,  6.86it/s]\n",
            "100%|██████████| 27/27 [00:03<00:00,  7.19it/s]\n",
            "100%|██████████| 27/27 [00:03<00:00,  8.30it/s]\n",
            "100%|██████████| 57/57 [00:09<00:00,  6.32it/s]\n",
            "100%|██████████| 61/61 [00:08<00:00,  7.43it/s]\n",
            "100%|██████████| 65/65 [00:09<00:00,  7.18it/s]\n",
            "100%|██████████| 69/69 [00:09<00:00,  7.40it/s]\n",
            "100%|██████████| 43/43 [00:06<00:00,  6.63it/s]\n",
            "100%|██████████| 33/33 [00:03<00:00,  8.37it/s]\n",
            "100%|██████████| 75/75 [00:10<00:00,  7.41it/s]\n",
            "100%|██████████| 55/55 [00:07<00:00,  7.20it/s]\n",
            "100%|██████████| 47/47 [00:06<00:00,  7.51it/s]\n",
            "100%|██████████| 37/37 [00:05<00:00,  6.82it/s]\n",
            "100%|██████████| 32/32 [00:03<00:00, 10.44it/s]\n",
            "100%|██████████| 35/35 [00:04<00:00,  7.67it/s]\n"
          ]
        }
      ],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1618146136957
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp = np.array(temp)\n",
        "data = temp.transpose()"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1618146193656
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 获取特征\n",
        "X = np.vstack(data[:, 0])\n",
        "\n",
        "# 获取标签\n",
        "Y = np.array(data[:, 1])\n",
        "print('X的特征尺寸是：',X.shape)\n",
        "print('Y的特征尺寸是：',Y.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X的特征尺寸是： (1000, 128)\n",
            "Y的特征尺寸是： (1000,)\n"
          ]
        }
      ],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1618146205857
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 在Keras库中：to_categorical就是将类别向量转换为二进制（只有0和1）的矩阵类型表示\n",
        "Y = to_categorical(Y)"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1618146212155
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''最终数据'''\n",
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 128)\n",
            "(1000, 20)\n"
          ]
        }
      ],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1618146215848
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state = 1, stratify=Y)\n",
        "print('训练集的大小',len(X_train))\n",
        "print('测试集的大小',len(X_test))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "训练集的大小 750\n",
            "测试集的大小 250\n"
          ]
        }
      ],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1618146235284
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(-1, 16, 8, 1)\n",
        "X_test = X_test.reshape(-1, 16, 8, 1)"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1618146240319
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 建立模型"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 搭建CNN网络"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "# 输入的大小\n",
        "input_dim = (16, 8, 1)\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding = \"same\", activation = \"tanh\", input_shape = input_dim))# 卷积层\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))# 最大池化\n",
        "model.add(Conv2D(128, (3, 3), padding = \"same\", activation = \"tanh\")) #卷积层\n",
        "model.add(MaxPool2D(pool_size=(2, 2))) # 最大池化层\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Flatten()) # 展开\n",
        "model.add(Dense(1024, activation = \"tanh\"))\n",
        "model.add(Dense(20, activation = \"softmax\")) # 输出层：20个units输出20个类的概率\n",
        "\n",
        "# 编译模型，设置损失函数，优化方法以及评价标准\n",
        "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1618146307702
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 16, 8, 64)         640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 8, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 8, 4, 128)         73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 4, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 4, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 20)                20500     \n",
            "=================================================================\n",
            "Total params: 1,144,596\n",
            "Trainable params: 1,144,596\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1618146327079
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 训练模型\n",
        "model.fit(X_train, Y_train, epochs = 20, batch_size = 15, validation_data = (X_test, Y_test))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 750 samples, validate on 250 samples\n",
            "Epoch 1/20\n",
            "750/750 [==============================] - 19s 26ms/sample - loss: 2.8676 - accuracy: 0.1347 - val_loss: 2.6953 - val_accuracy: 0.1840\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "Epoch 2/20\n",
            "750/750 [==============================] - 0s 369us/sample - loss: 2.5169 - accuracy: 0.2440 - val_loss: 2.6012 - val_accuracy: 0.2360\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "Epoch 3/20\n",
            "750/750 [==============================] - 0s 370us/sample - loss: 2.2814 - accuracy: 0.3120 - val_loss: 2.4125 - val_accuracy: 0.2920\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "Epoch 4/20\n",
            "750/750 [==============================] - 0s 365us/sample - loss: 2.0839 - accuracy: 0.3520 - val_loss: 2.4674 - val_accuracy: 0.2760\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "Epoch 5/20\n",
            "750/750 [==============================] - 0s 394us/sample - loss: 1.8885 - accuracy: 0.4267 - val_loss: 2.4941 - val_accuracy: 0.3120\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "Epoch 6/20\n",
            "750/750 [==============================] - 0s 375us/sample - loss: 1.7580 - accuracy: 0.4667 - val_loss: 2.5075 - val_accuracy: 0.2880\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "Epoch 7/20\n",
            "750/750 [==============================] - 0s 372us/sample - loss: 1.5541 - accuracy: 0.5187 - val_loss: 2.5463 - val_accuracy: 0.3200\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "Epoch 8/20\n",
            "750/750 [==============================] - 0s 359us/sample - loss: 1.3780 - accuracy: 0.5907 - val_loss: 2.6920 - val_accuracy: 0.3280\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "Epoch 9/20\n",
            "750/750 [==============================] - 0s 364us/sample - loss: 1.2526 - accuracy: 0.6253 - val_loss: 2.7060 - val_accuracy: 0.3320\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "Epoch 10/20\n",
            "750/750 [==============================] - 0s 360us/sample - loss: 1.1301 - accuracy: 0.6680 - val_loss: 2.6507 - val_accuracy: 0.3680\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "Epoch 11/20\n",
            "750/750 [==============================] - 0s 371us/sample - loss: 1.0179 - accuracy: 0.7000 - val_loss: 2.9737 - val_accuracy: 0.3040\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "Epoch 12/20\n",
            "750/750 [==============================] - 0s 363us/sample - loss: 0.8886 - accuracy: 0.7280 - val_loss: 3.1785 - val_accuracy: 0.3480\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "Epoch 13/20\n",
            "750/750 [==============================] - 0s 368us/sample - loss: 0.8993 - accuracy: 0.7307 - val_loss: 3.3839 - val_accuracy: 0.3480\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "Epoch 14/20\n",
            "750/750 [==============================] - 0s 371us/sample - loss: 0.8087 - accuracy: 0.7520 - val_loss: 3.2484 - val_accuracy: 0.3480\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "Epoch 15/20\n",
            "750/750 [==============================] - 0s 362us/sample - loss: 0.6779 - accuracy: 0.7893 - val_loss: 3.3512 - val_accuracy: 0.3960\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "Epoch 16/20\n",
            "750/750 [==============================] - 0s 368us/sample - loss: 0.5466 - accuracy: 0.8507 - val_loss: 3.4273 - val_accuracy: 0.3800\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "Epoch 17/20\n",
            "750/750 [==============================] - 0s 361us/sample - loss: 0.5194 - accuracy: 0.8587 - val_loss: 3.7276 - val_accuracy: 0.3880\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "Epoch 18/20\n",
            "750/750 [==============================] - 0s 370us/sample - loss: 0.4734 - accuracy: 0.8733 - val_loss: 3.9197 - val_accuracy: 0.3680\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "Epoch 19/20\n",
            "750/750 [==============================] - 0s 364us/sample - loss: 0.4250 - accuracy: 0.8787 - val_loss: 3.7749 - val_accuracy: 0.3920\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "Epoch 20/20\n",
            "750/750 [==============================] - 0s 361us/sample - loss: 0.3319 - accuracy: 0.9120 - val_loss: 3.9230 - val_accuracy: 0.4120\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 23,
          "data": {
            "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7fc9ac1faef0>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1618146360980
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 预测测试集"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(test_dir, file_ext=\"*.wav\"):\n",
        "    feature = []\n",
        "    for fn in tqdm(glob.glob(os.path.join(test_dir, file_ext))[:]): # 遍历数据集的所有文件\n",
        "        X, sample_rate = librosa.load(fn,res_type='kaiser_fast')\n",
        "        mels = np.mean(librosa.feature.melspectrogram(y=X,sr=sample_rate).T,axis=0) # 计算梅尔频谱(mel spectrogram),并把它作为特征\n",
        "        feature.extend([mels])\n",
        "    return feature"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1618146391500
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = extract_features('./test_a/')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2000/2000 [04:30<00:00,  7.39it/s]\n"
          ]
        }
      ],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1618146667721
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = np.vstack(X_test)\n",
        "predictions = model.predict(X_test.reshape(-1, 16, 8, 1))"
      ],
      "outputs": [],
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1618146672824
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = np.argmax(predictions, axis = 1)\n",
        "preds = [label_dict_inv[x] for x in preds]\n",
        "\n",
        "path = glob.glob('./test_a/*.wav')\n",
        "result = pd.DataFrame({'name':path, 'label': preds})\n",
        "\n",
        "result['name'] = result['name'].apply(lambda x: x.split('/')[-1])\n",
        "result.to_csv('submit.csv',index=None)"
      ],
      "outputs": [],
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1618146679131
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result.describe()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 30,
          "data": {
            "text/plain": "                  name    label\ncount             2000     2000\nunique            2000       20\ntop     IK77EC2GUL.wav  pickles\nfreq                 1      179",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2000</td>\n      <td>2000</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>2000</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>IK77EC2GUL.wav</td>\n      <td>pickles</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>1</td>\n      <td>179</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 30,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1618146731241
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 32,
          "data": {
            "text/plain": "             name    label\n0  00B7EQA2MJ.wav  gummies\n1  00ISO9XPIQ.wav  cabbage\n2  01CF45NDOQ.wav     aloe\n3  039RA8859M.wav   burger\n4  03KSQR5VOP.wav   drinks",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00B7EQA2MJ.wav</td>\n      <td>gummies</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00ISO9XPIQ.wav</td>\n      <td>cabbage</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>01CF45NDOQ.wav</td>\n      <td>aloe</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>039RA8859M.wav</td>\n      <td>burger</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>03KSQR5VOP.wav</td>\n      <td>drinks</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 32,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1618146767353
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ./test_a/*.wav | wc -l"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2000\r\n"
          ]
        }
      ],
      "execution_count": 33,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!wc -l submit.csv"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2001 submit.csv\r\n"
          ]
        }
      ],
      "execution_count": 34,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "tianchi_metadata": {
      "competitions": [],
      "datasets": [
        {
          "id": "96728",
          "title": "获取数据集标题失败"
        }
      ],
      "description": "",
      "notebookId": "185525",
      "source": "dsw"
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}