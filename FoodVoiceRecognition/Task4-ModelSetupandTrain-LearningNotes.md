### 1. Notebook ###

运行结果： [Task4-ModelSetupandTrain.ipynb](https://github.com/frankyangdev/NLP-Learning/blob/main/FoodVoiceRecognition/Task4-ModelSetupandTrain.ipynb)

### 2. Convolution Neural Network (CNN) ###

CNN由纽约大学的Yann LeCun于1998年提出。CNN本质上是一个多层感知机，其成功的原因关键在于它所采用的局部连接和共享权值的方式，一方面减少了的权值的数量使得网络易于优化，另一方面降低了过拟合的风险。CNN是神经网络中的一种，它的权值共享网络结构使之更类似于生物神经网络，降低了网络模型的复杂度，减少了权值的数量。该优点在网络的输入是多维图像时表现的更为明显，使图像可以直接作为网络的输入，避免了传统识别算法中复杂的特征提取和数据重建过程。在二维图像处理上有众多优势，如网络能自行抽取图像特征包括颜色、纹理、形状及图像的拓扑结构；在处理二维图像问题上，特别是识别位移、缩放及其它形式扭曲不变性的应用上具有良好的鲁棒性和运算效率等。

CNN本身可以采用不同的神经元和学习规则的组合形式。

CNN具有一些传统技术所没有的优点：良好的容错能力、并行处理能力和自学习能力，可处理环境信息复杂，背景知识不清楚，推理规则不明确情况下的问题，允许样品有较大的缺损、畸变，运行速度快，自适应性能好，具有较高的分辨率。它是通过结构重组和减少权值将特征抽取功能融合进多层感知器，省略识别前复杂的图像特征抽取过程。
 
卷积神经网络属于前馈网络的一种，是一种专门处理类似网格数据的神经网络，其特点就是每一层神经元只响应前一层的局部范围内的神经元。
卷积网络一般由：卷积运算+非线性操作（RELU）+池化 +若干全连接层。


般情况下，CNN的结构形式是：输入层--> Conv层 --> Pooling层 --> (重复Conv、Pooling层) … --> FC(Full-connected)层 --> 输出结果。通常输入层大小一般为2的整数倍，如32,64,96,224,384等。通常卷积层使用较小的filter，如3*3，最大也就5*5。Pooling层用于对卷积结果进行降低维度，例如选择2*2的区域对卷积层进行降低维度，则选择2*2区域的最大值作为输出，这样卷积层的维度就降为之前一半。

 一般地，CNN的基本结构包括两层，其一为特征提取层，每个神经元的输入与前一层的局部接受域相连，并提取该局部的特征。一旦该局部特征被提取后，它与其它特征间的位置关系也随之确定下来；其二是特征映射层，网络的每个计算层由多个特征映射组成，每个特征映射是一个平面，平面上所有神经元的权值相等。特征映射结构采用影响函数核小的sigmoid函数作为卷积网络的激活函数，使得特征映射具有位移不变性。此外，由于一个映射面上的神经元共享权值，因而减少了网络自由参数的个数。卷积神经网络中的每一个卷积层都紧跟着一个用来求局部平均与二次提取的计算层，这种特有的两次特征提取结构减小了特征分辨率。



[卷积神经网络(CNN)基础介绍](https://blog.csdn.net/fengbingchun/article/details/50529500)
